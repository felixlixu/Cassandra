package org.apache.cassandra.service;

import java.io.IOException;
import java.lang.management.ManagementFactory;
import java.net.InetAddress;
import java.nio.ByteBuffer;
import java.util.ArrayList;
import java.util.Collection;
import java.util.Collections;
import java.util.List;
import java.util.concurrent.TimeoutException;

import javax.management.MBeanServer;
import javax.management.ObjectName;

import org.apache.cassandra.concurrent.Stage;
import org.apache.cassandra.concurrent.StageManager;
import org.apache.cassandra.config.DatabaseDescriptor;
import org.apache.cassandra.db.CounterMutation;
import org.apache.cassandra.db.IMutation;
import org.apache.cassandra.db.ReadCommand;
import org.apache.cassandra.db.Row;
import org.apache.cassandra.db.RowMutation;
import org.apache.cassandra.db.Table;
import org.apache.cassandra.dht.Token;
import org.apache.cassandra.gms.Gossiper;
import org.apache.cassandra.locator.AbstractReplicationStrategy;
import org.apache.cassandra.locator.IEndpointSnitch;
import org.apache.cassandra.net.Message;
import org.apache.cassandra.net.MessageProducer;
import org.apache.cassandra.net.MessagingService;
import org.apache.cassandra.service.StorageService.Verb;
import org.apache.cassandra.thrift.ConsistencyLevel;
import org.apache.cassandra.thrift.UnavailableException;
import org.apache.cassandra.utils.ByteBufferUtil;
import org.apache.cassandra.utils.FBUtilities;
import org.apache.cassandra.utils.LatencyTracker;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

public class StorageProxy implements StorageProxyMBean {

	private static final Logger logger = LoggerFactory
			.getLogger(StorageProxy.class);

	private static final LatencyTracker readStats = new LatencyTracker();
	private static final LatencyTracker writeStates=new LatencyTracker();
	
	public static final StorageProxy instance = new StorageProxy();

	private static final WritePerformer standardWritePerformer;

	private static final WritePerformer counterWritePerformer;

	private static WritePerformer counterWriteOnCoordinatorPerformer;

	private static boolean OPTIMIZE_LOCAL_REQUESTS=true;

	public static List<Row> read(List<ReadCommand> commands,
			ConsistencyLevel consistency_level) throws UnavailableException, TimeoutException {
		if (StorageService.instance.isBootstrapMode())
			throw new UnavailableException();
		long startTime = System.nanoTime();
		List<Row> rows;
		try {
			rows = fetchRows(commands, consistency_level);
		} finally {
			readStats.addNano(System.nanoTime() - startTime);
		}
		return rows;
	}

	private StorageProxy() {
	
	}

	static {
		MBeanServer mbs = ManagementFactory.getPlatformMBeanServer();

		try {
			mbs.registerMBean(new StorageProxy(), new ObjectName(
					"org.apache.cassandra.db:type=StorageProxy"));
		} catch (Exception e) {
			throw new RuntimeException(e);
		}

		standardWritePerformer = new WritePerformer() {
			public void apply(IMutation mutation,
					Collection<InetAddress> targets,
					IWriteResponseHandler responseHandler,
					String localDataCenter, ConsistencyLevel consistency_level)
					throws IOException, TimeoutException {
				assert mutation instanceof RowMutation;
				sendToHintedEndpoints((RowMutation) mutation, targets,
						responseHandler, localDataCenter, consistency_level);
			}
		};

		counterWritePerformer = new WritePerformer() {
			public void apply(IMutation mutation,
					Collection<InetAddress> targets,
					IWriteResponseHandler responseHandler,
					String localDataCenter, ConsistencyLevel consistency_level)
					throws IOException {
				if (logger.isDebugEnabled())
					logger.debug("insert writing local & replicate "
							+ mutation.toString(true));

				Runnable runnable = counterWriteTask(mutation, targets,
						responseHandler, localDataCenter, consistency_level);
				runnable.run();
			}
		};

        counterWriteOnCoordinatorPerformer = new WritePerformer()
        {
            public void apply(IMutation mutation,
                              Collection<InetAddress> targets,
                              IWriteResponseHandler responseHandler,
                              String localDataCenter,
                              ConsistencyLevel consistency_level)
            throws IOException
            {
                if (logger.isDebugEnabled())
                    logger.debug("insert writing local & replicate " + mutation.toString(true));

                Runnable runnable = counterWriteTask(mutation, targets, responseHandler, localDataCenter, consistency_level);
                StageManager.getStage(Stage.MUTATION).execute(runnable);
            }
        };
	}

	/**
	 * This function executes local and remote reads, and blocks for the results 
	 **/
	private static List<Row> fetchRows(List<ReadCommand> initialCommands,
			ConsistencyLevel consistency_level) throws UnavailableException, TimeoutException {
		List<Row> rows = new ArrayList<Row>(initialCommands.size());
		List<ReadCommand> commandsToRetry = Collections.emptyList();
		do {
			//create command set and readCallback array.
			List<ReadCommand> commands = commandsToRetry.isEmpty() ? initialCommands
					: commandsToRetry;
			ReadCallback<Row>[] readCallbacks = new ReadCallback[commands
					.size()];
			if (!commandsToRetry.isEmpty()) {
				logger.debug("Retrying {} commands", commandsToRetry.size());
			}

			for (int i = 0; i < commands.size(); i++) {
				ReadCommand command = commands.get(i);
				assert !command.isDigestQuery();
				logger.debug("Command/ConsistencyLevel is {}/{}", command,
						consistency_level);
				//get token from key. and then get live endpoints from token.
				List<InetAddress> endpoints = StorageService.instance
						.getLiveNaturalEndpoints(command.table, command.key);
				DatabaseDescriptor.getEndpointSnitch().sortByProximity(FBUtilities.getBroadcastAddress(),endpoints);
				RowDigestResolver resolver=new RowDigestResolver(command.table,command.key);
				ReadCallback<Row> handler=getReadCallback(resolver,command,consistency_level,endpoints);
				handler.assureSufficientLiveNodes();
				assert !handler.endpoints.isEmpty();
				readCallbacks[i]=handler;
				
				InetAddress dataPoint=handler.endpoints.get(0);
				if(dataPoint.equals(FBUtilities.getBroadcastAddress())&&OPTIMIZE_LOCAL_REQUESTS){
					logger.debug("reading data locally");
					StageManager.getStage(Stage.READ).execute(new LocalReadRunnable(command,handler));
				}
				else{
					logger.debug("reading data from {}", dataPoint);
					MessagingService.instance().sendRR(command,dataPoint,handler);
				}
				if(handler.endpoints.size()==1)
					continue;
				ReadCommand digestCommand=command.copy();
				digestCommand.setDigestQuery(true);
				MessageProducer producer=null;
				for(InetAddress digestPoint:handler.endpoints.subList(1, handler.endpoints.size())){
					if(digestPoint.equals(FBUtilities.getBroadcastAddress())){
						logger.debug("reading digest locally");
						StageManager.getStage(Stage.READ).execute(new LocalReadRunnable(digestCommand, handler));
					}
					else{
						logger.debug("reading digest from {}",digestPoint);
						if(producer==null){
							producer=new CachingMessageProducer(digestCommand);
						}
						MessagingService.instance().sendRR(producer, digestPoint, handler);
					}
				}
			}
            // read results and make a second pass for any digest mismatches
            List<ReadCommand> repairCommands = null;
            List<RepairCallback> repairResponseHandlers = null;
            for (int i = 0; i < commands.size(); i++)
            {
                ReadCallback<Row> handler = readCallbacks[i];
                ReadCommand command = commands.get(i);
                try
                {
                    long startTime2 = System.currentTimeMillis();
                    Row row = handler.get();
                    if (row != null)
                    {
                        command.maybeTrim(row);
                        rows.add(row);
                    }

                    if (logger.isDebugEnabled())
                        logger.debug("Read: " + (System.currentTimeMillis() - startTime2) + " ms.");
                }
                catch (TimeoutException ex)
                {
                    if (logger.isDebugEnabled())
                        logger.debug("Read timeout: {}", ex.toString());
                    throw ex;
                }
                catch (DigestMismatchException ex)
                {
                    if (logger.isDebugEnabled())
                        logger.debug("Digest mismatch: {}", ex.toString());
                    RowRepairResolver resolver = new RowRepairResolver(command.table, command.key);
                    RepairCallback repairHandler = new RepairCallback(resolver, handler.endpoints);

                    if (repairCommands == null)
                    {
                        repairCommands = new ArrayList<ReadCommand>();
                        repairResponseHandlers = new ArrayList<RepairCallback>();
                    }
                    repairCommands.add(command);
                    repairResponseHandlers.add(repairHandler);

                    MessageProducer producer = new CachingMessageProducer(command);
                    for (InetAddress endpoint : handler.endpoints)
                        MessagingService.instance().sendRR(producer, endpoint, repairHandler);
                } catch (IOException e) {
					e.printStackTrace();
				}
            }

            if (commandsToRetry != Collections.EMPTY_LIST)
                commandsToRetry.clear();

            // read the results for the digest mismatch retries
            if (repairResponseHandlers != null)
            {
                for (int i = 0; i < repairCommands.size(); i++)
                {
                    ReadCommand command = repairCommands.get(i);
                    RepairCallback handler = repairResponseHandlers.get(i);
                    // wait for the repair writes to be acknowledged, to minimize impact on any replica that's
                    // behind on writes in case the out-of-sync row is read multiple times in quick succession
                    FBUtilities.waitOnFutures(handler.resolver.repairResults, DatabaseDescriptor.getRpcTimeout());

                    Row row;
                    try
                    {
                        row = handler.get();
                    }
                    catch (DigestMismatchException e)
                    {
                        throw new AssertionError(e); // full data requested from each node here, no digests should be sent
                    }

                    ReadCommand retryCommand = command.maybeGenerateRetryCommand(handler, row);
                    if (retryCommand != null)
                    {
                        logger.debug("issuing retry for read command");
                        if (commandsToRetry == Collections.EMPTY_LIST)
                            commandsToRetry = new ArrayList<ReadCommand>();
                        commandsToRetry.add(retryCommand);
                        continue;
                    }

                    if (row != null)
                    {
                        command.maybeTrim(row);
                        rows.add(row);
                    }
                }
            }
		} while (!commandsToRetry.isEmpty());
		return rows;
	}
	
  	private static <T> ReadCallback<T> getReadCallback(
			RowDigestResolver resolver, ReadCommand command,
			ConsistencyLevel consistency_level,List<InetAddress> endpoints) {
		if(consistency_level==ConsistencyLevel.LOCAL_QUORUM||consistency_level==ConsistencyLevel.EACH_QUORUM){
			return new DatacenterReadCallback(resolver,consistency_level,command,endpoints);
		}
		return new ReadCallback(resolver,consistency_level,command,endpoints);
	}

	protected static Runnable counterWriteTask(IMutation mutation,
			Collection<InetAddress> targets,
			IWriteResponseHandler responseHandler, String localDataCenter,
			ConsistencyLevel consistency_level) {
		// TODO Auto-generated method stub
		return null;
	}

	protected static void sendToHintedEndpoints(RowMutation mutation,
			Collection<InetAddress> targets,
			IWriteResponseHandler responseHandler, String localDataCenter,
			ConsistencyLevel consistency_level) {
		// TODO Auto-generated method stub

	}

	public interface WritePerformer {
		public void apply(IMutation mutation, Collection<InetAddress> target,
				IWriteResponseHandler responseHandler, String localDataCenter,
				ConsistencyLevel consistency_level) throws IOException,
				TimeoutException;
	}

	static class LocalReadRunnable extends DroppableRunnable{

		private ReadCommand command;
		private ReadCallback<Row> handler;

		public LocalReadRunnable(ReadCommand command, ReadCallback<Row> handler) {
			super(StorageService.Verb.READ);
			this.command=command;
			this.handler=handler;
		}

		@Override
		protected void runMayThrow() throws Exception {
			// TODO Auto-generated method stub
			
		}
		
	}
	
	private static abstract class DroppableRunnable implements Runnable{
		private final Verb verb;
		private final long constructionTime=System.currentTimeMillis(); 

		public DroppableRunnable(Verb verb) {
			this.verb=verb;
		}

		public final void run(){
			if(System.currentTimeMillis()>constructionTime+DatabaseDescriptor.getRpcTimeout()){
				MessagingService.instance().incrementDroppedMessage(verb);
				return;
			}
			try{
				runMayThrow();
			}catch(Exception e){
				throw new RuntimeException();
			}
		}
		
		abstract protected void runMayThrow() throws Exception;
	}
	/**
	 * Use this method to have these Mutations applied across all replicas.
	 * This method will take care of possibility of a replica being down and hint the data across to some other replia.
	 **/
	public static void mutate(List<? extends IMutation> mutations,
			ConsistencyLevel consistency_level) throws UnavailableException {
		 logger.debug("Mutations/ConsistencyLevel are {}/{}", mutations, consistency_level);
		 final String localDataCenter=DatabaseDescriptor.getEndpointSnitch().getDatacenter(FBUtilities.getBroadcastAddress());
		 
		 long startTime=System.nanoTime();
		 List<IWriteResponseHandler> responseHandlers=new ArrayList<IWriteResponseHandler>();
		 
		 IMutation mostRecentMutation=null;
		 try{
			 for(IMutation mutation:mutations){
				 mostRecentMutation=mutation;
				 if(mutation instanceof CounterMutation){
					 responseHandlers.add(mutateCounter((CounterMutation)mutation,localDataCenter));
				 }else{
					 responseHandlers.add(performWrite(mutation,consistency_level,localDataCenter,standardWritePerformer));
				 }
			 }
			 for(IWriteResponseHandler responseHandler:responseHandlers){
				 responseHandler.get();
			 }
		 }catch(TimeoutException ex){
			 
		 }catch(IOException e){
			 
		 }finally{
			 writeStates.addNano(System.nanoTime()-startTime);
		 }
	}

	private static IWriteResponseHandler performWrite(IMutation mutation,
			ConsistencyLevel consistency_level, String localDataCenter,
			WritePerformer performer) throws UnavailableException, IOException, TimeoutException {
		String table=mutation.getTable();
		AbstractReplicationStrategy rs=Table.open(table).getReplicationStrategy();
		Collection<InetAddress> writeEndpoints=getWriteEndpoints(table,mutation.key());
		
		IWriteResponseHandler responseHandler=rs.getWriteResponseHandler(writeEndpoints,consistency_level);
		
		responseHandler.assureSufficientLiveNodes();
		performer.apply(mutation,writeEndpoints,responseHandler,localDataCenter,consistency_level);
		return responseHandler;
	}

	private static Collection<InetAddress> getWriteEndpoints(String table,
			ByteBuffer key) {
		StorageService ss=StorageService.instance;
		Token tk=StorageService.getPartitioner().getToken(key);
		List<InetAddress> naturalEndpoints=ss.getLiveNaturalEndpoints(table, tk);
		return ss.getTokenMetadata().getWriteEndpoints(tk,table,naturalEndpoints);
	}

	private static IWriteResponseHandler mutateCounter(
			CounterMutation mutation, String localDataCenter) throws UnavailableException, IOException, TimeoutException {
		InetAddress endpoint=findSuitableEndpoint(mutation.getTable(),mutation.key(),localDataCenter);
		if(endpoint.equals(FBUtilities.getBroadcastAddress())){
			return applyCounterMutationOnCoordinator(mutation,localDataCenter);
		}else{
			String table=mutation.getTable();
			AbstractReplicationStrategy rs=Table.open(table).getReplicationStrategy();
			Collection<InetAddress> writeEndpoints=getWriteEndpoints(table,mutation.key());
			rs.getWriteResponseHandler(writeEndpoints,mutation.consistency()).assureSufficientLiveNodes();
			IWriteResponseHandler  responseHandler=WriteResponseHandler.create(endpoint);
			Message message=mutation.makeMutationMessage(Gossiper.instance.getVersion(endpoint));
            if (logger.isDebugEnabled())
                logger.debug("forwarding counter update of key " + ByteBufferUtil.bytesToHex(mutation.key()) + " to " + endpoint);
            MessagingService.instance().sendRR(message, endpoint, responseHandler);
			return responseHandler;
		}
	}

	private static IWriteResponseHandler applyCounterMutationOnCoordinator(
			CounterMutation mutation, String localDataCenter) throws UnavailableException, IOException, TimeoutException {
		return performWrite(mutation,mutation.consistency(),localDataCenter,counterWriteOnCoordinatorPerformer);
	}

	private static InetAddress findSuitableEndpoint(String table,
			ByteBuffer key, String localDataCenter) throws UnavailableException {
		IEndpointSnitch snitch=DatabaseDescriptor.getEndpointSnitch();
		List<InetAddress> endpoints=StorageService.instance.getLiveNaturalEndpoints(table, key);
		if(endpoints.isEmpty()){
			throw new UnavailableException();
		}
		List<InetAddress> localEndpoints=new ArrayList<InetAddress>();
		for(InetAddress endpoint:endpoints){
			if(snitch.getDatacenter(endpoint).equals(localDataCenter)){
				localEndpoints.add(endpoint);
			}
		}
		if(localEndpoints.isEmpty()){
			snitch.sortByProximity(FBUtilities.getBroadcastAddress(), endpoints);
			return endpoints.get(0);
		}else{
			return localEndpoints.get(FBUtilities.threadLocalRandom().nextInt(localEndpoints.size()));
		}
	}
	
}
